llm:
  api_type: "open_llm" # or openai
  base_url: 'http://localhost:8000/v1' 
  model: "Meta-Llama-3-8B-Instruct"
  api_key: "EMPTY" # 本地服务通常不需要 key

embedding:
  api_type: "hf"  # or  ollama / openai.
  # base_url: "https://cfcus02.opapi.win/v1"  # or forward url / other llm url
  api_key: "YOUR_API_KEY"
  model: "/root/model/BAAI/bge-m3"
  cache_dir: ""
  dimensions: 1024
  max_token_size: 8102
  embed_batch_size: 128
  embedding_func_max_async: 16
 
data_root:  "/home/Gitworks/GraphRAG/Data" # Root directory for data


working_dir: ./Output # Result directory for the experiment
exp_name:  test_experiment # Experiment name 
